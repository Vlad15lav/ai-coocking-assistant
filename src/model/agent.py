from operator import itemgetter

from langchain_core.prompts import PromptTemplate
from langchain_core.runnables import RunnableLambda, RunnablePassthrough
from langchain_core.output_parsers import StrOutputParser
from langchain_core.messages import AIMessage, HumanMessage

from model.prompt import (
    PROMPT_CLASSIFIER,
    PROMPT_ASSISTANT,
    PROMPT_RECOMMENDER,
    PROMPT_GENERATER,
    PROMPT_SEARCH,
    PROMPT_ENTITY_MEMORY
)
from tools.utils import (
    clean_input,
    format_docs,
    format_docs_with_links,
    search_image
)


class AgentSystem:
    """AI Coocking Assistant
    """
    def __init__(self, llm, retriever, k=6):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∞–≥–µ–Ω—Ç–∞

        Args:
            llm: Large Language Model
            retriever: FAISS Index Retriever
            k: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ–æ–±—â–µ–Ω–∏–π –≤ –ø–∞–º—è—Ç–∏ –∞–≥–µ–Ω—Ç–∞
        """
        self.llm = llm
        self.retriever = retriever

        self.k = k

        self.chat_history = []
        self.memory_entity = self.get_memory_entity_chain()

        self.assistant_chain = self.get_assistant_chain()
        self.recommender_chain = self.get_recommender_chain()
        self.generater_chain = self.get_generater_chain()
        self.search_chain = self.get_search_chain()

        self.full_chain = self.initial_chain()

    def invoke(self, query: str):
        """–í—ã–∑–æ–≤ —Ü–µ–ø–æ—á–∫–∏

        Args:
            query (str): –ó–∞–ø—Ä–æ—Å –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è

        Returns:
            dict: –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–∏—Å—Ç–µ–º—ã —Ü–µ–ø–æ—á–µ–∫
        """
        result = self.full_chain.invoke({
            "input": query,
            "chat_history": self.chat_history
            })

        if result['task'] == "Unknown":
            return result

        self.chat_history.append(HumanMessage(content=query))

        if result['task'] == "Search Image":
            self.chat_history.append(AIMessage(content="–ù–∞—à–µ–ª –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ."))
        else:
            summary_response = self.memory_entity.invoke(result['output'])
            self.chat_history.append(AIMessage(content=summary_response))

        self.chat_history = self.chat_history[-self.k:]

        return result

    def initial_memory(self, chat_history: list):
        """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–º—è—Ç–∏ –¥–ª—è –∞–≥–µ–Ω—Ç–∞

        Args:
            chat_history (list): –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞
        """
        self.chat_history = chat_history

    def get_chat_history(self):
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ç–µ–∫—É—â–∏–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ –ø–∞–º—è—Ç–∏

        Returns:
            chat_history (list): –ò—Å—Ç–æ—Ä–∏—è —á–∞—Ç–∞
        """
        return self.chat_history

    def get_memory_entity_chain(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π

        Returns:
            memory_entity: –¶–µ–ø–æ—á–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π –≤ –ø–∞–º—è—Ç–∏
        """
        memory_entity = (
            PromptTemplate.from_template(PROMPT_ENTITY_MEMORY)
            | self.llm
            | StrOutputParser()
        )

        return memory_entity

    def initial_chain(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –∞–≥–µ–Ω—Ç–æ–≤

        Returns:
            full_chain: –ò—Ç–æ–≥–æ–≤–∞—è —Ü–µ–ø–æ—á–∫–∞ —Å–∏—Å—Ç–µ–º—ã
        """
        classifier_chain = (
            clean_input
            | PromptTemplate.from_template(PROMPT_CLASSIFIER)
            | self.llm
            | StrOutputParser()
        )

        full_chain = (
            {
                "input": itemgetter("input"),
                "topic": itemgetter("input") | classifier_chain,
                "chat_history": itemgetter("chat_history")
            }
            | RunnableLambda(self.route_chain)
        )

        return full_chain

    def get_assistant_chain(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –¥–ª—è –¥–ª—è –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç–∞
        """
        assistant_chain = (
            PromptTemplate.from_template(PROMPT_ASSISTANT)
            | self.llm
            | {"output": lambda x: x.content, "task": lambda x: "About Me"}
        )

        return assistant_chain

    def get_recommender_chain(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –¥–ª—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±–ª—é–¥–∞ –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        recommender_chain = (
            {
                "descripition": itemgetter("input")
                | self.retriever
                | format_docs_with_links,
                "query": itemgetter("input"),
                "chat_history": itemgetter("chat_history")
            }
            | PromptTemplate.from_template(PROMPT_RECOMMENDER)
            | self.llm
            | {"output": lambda x: x.content, "task": lambda x: "Recommend"}
        )

        return recommender_chain

    def get_generater_chain(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–¥–µ–∏ –¥–ª—è –Ω–æ–≤–æ–≥–æ –±–ª—é–¥–∞
        –ø–æ –∑–∞–ø—Ä–æ—Å—É –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
        """
        generater_chain = (
            {
                "descripition": itemgetter("input")
                | self.retriever
                | format_docs,
                "query": itemgetter("input"),
                "chat_history": itemgetter("chat_history")
            }
            | PromptTemplate.from_template(PROMPT_GENERATER)
            | self.llm
            | {"output": lambda x: x.content, "task": lambda x: "Generate"}
        )

        return generater_chain

    def get_search_chain(self):
        """–°–æ–∑–¥–∞–Ω–∏–µ —Ü–µ–ø–æ—á–∫–∏ –¥–ª—è –ø–æ–∏—Å–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –±–ª—é–¥–∞
        —Å –ø–æ–º–æ—â—å—é DuckDuckGo Search
        """
        search_chain = (
            {
                "query": RunnablePassthrough(),
                "chat_history": itemgetter("chat_history")
            }
            | PromptTemplate.from_template(PROMPT_SEARCH)
            | self.llm
            | {"query": lambda x: x.content}
            | search_image
        )

        return search_chain

    def route_chain(self, dict_chain):
        """–ú–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏—è –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –ø–æ —Ü–µ–ø–æ—á–∫–∞–º
        """
        info_class = dict_chain["topic"].lower()

        if "hello" in info_class or "about me" in info_class:
            return self.assistant_chain
        elif "recommended" in info_class:
            return self.recommender_chain
        elif "generate" in info_class:
            return self.generater_chain
        elif "image food" in info_class:
            return self.search_chain

        other_task = {
            "output": (
                "–Ø –Ω–µ –ø–æ–Ω—è–ª –∑–∞–ø—Ä–æ—Å–∞.ü§Ø " +
                "–ü–æ–ø—Ä–æ–±—É–π –ø–µ—Ä–µ—Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∞—Ç—å!ü§î"
                ),
            "task": "Unknown"
        }

        return other_task
